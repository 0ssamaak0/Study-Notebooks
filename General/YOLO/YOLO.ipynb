{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_config = [\n",
    "    (7, 64, 2, 3), # kernel_size, filters, stride, padding\n",
    "    \"M\", # Maxpooling\n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 256, 1, 0), (3, 512, 1, 1), 4], # 4 is the number of repetitions\n",
    "    (1, 512, 1, 0),\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias = False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, in_channels = 3, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # architecture_config is a list of tuples, strings, and lists\n",
    "        self.architecture = architecture_config\n",
    "        # in_channels is the number of channels of the input image\n",
    "        self.in_channels = in_channels\n",
    "        # device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # create the layers\n",
    "        self.darknet = self._create_conv_layers(self.architecture)\n",
    "        # create the fully connected layers\n",
    "        self.fcs = self._create_fcs(**kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x.to(self.device))\n",
    "        return self.fcs(torch.flatten(x, start_dim= 1))\n",
    "    \n",
    "    def _create_conv_layers(self, architecture):\n",
    "        # empty list to store the layers\n",
    "        layers = []\n",
    "        # in_channels is the number of channels of the input image\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == tuple:\n",
    "                # add a convolutional layer\n",
    "                layers += [CNNBlock(in_channels, out_channels=x[1], kernel_size = x[0], stride = x[2], padding = x[3])]\n",
    "                # update in_channels\n",
    "                in_channels = x[1]\n",
    "            if type(x) == str:\n",
    "                # add a maxpooling layer\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride = 2)]\n",
    "            if type(x) == list:\n",
    "                # This is a list contains 2 tuples and 1 int (number of repetitions)\n",
    "                conv1 = x[0]\n",
    "                conv2 = x[1]\n",
    "                num_repeats = x[2]\n",
    "                for _ in range(num_repeats):\n",
    "                    layers += [CNNBlock(in_channels, conv1[1], kernel_size = conv1[0], stride = conv1[2], padding = conv1[3])]\n",
    "                    layers += [CNNBlock(conv1[1], conv2[1], kernel_size = conv2[0], stride = conv2[2], padding = conv2[3])]\n",
    "                    # update in_channels\n",
    "                    in_channels = conv2[1]\n",
    "\n",
    "        return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "    \n",
    "    def _create_fcs(self, split_size, num_boxes, num_classes):\n",
    "        \"\"\"\n",
    "        split_size: The size of the image divided by the number of cells\n",
    "        num_boxes: The number of bounding boxes per cell\n",
    "        num_classes: The number of classes\n",
    "        \"\"\"\n",
    "        S, B, C = split_size, num_boxes, num_classes\n",
    "        return nn.Sequential(\n",
    "            # Flattens the input into a vector\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(1024 * S * S, 496), # Originally 4096\n",
    "            nn.Dropout(0.0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(496, S * S * (C + B * 5)) # ()\n",
    "        ).to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1470])\n"
     ]
    }
   ],
   "source": [
    "def test(split_size = 7, num_boxes = 2, num_classes = 20):\n",
    "    model = YOLOv1(split_size = split_size, num_boxes = num_boxes, num_classes = num_classes)\n",
    "    x = torch.randn((2, 3, 448, 448)) # (batch_size, channels, height, width)\n",
    "    print(model(x).shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- YOLO Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, S = 7, B = 2, C = 20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # mean squared error loss (sum reduction)\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        # set the weights\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "    \n",
    "    def forward(self, predictions, target):\n",
    "        # predictions: (batch_size, S * S * (C + B * 5))\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        # calculate IoU for the two bounding boxes\n",
    "        iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
    "        iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
    "\n",
    "        # concatenate the IoU values\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim = 0)\n",
    "        # get the max IoU values along the first dimension (the two bounding boxes)\n",
    "        iou_maxes, best_box = torch.max(ious, dim = 0)\n",
    "        # I_obj_i (1 if the object exists in the cell, 0 otherwise)\n",
    "        exists_box = target[..., 20].unsqueeze(3) # (batch_size, S, S, 1)\n",
    "\n",
    "\n",
    "        # ======== For Box Coordinates ======== #\n",
    "        # (best_box * predictions[..., 26:30] + (1 - best_box) * predictions[..., 21:25]) selects best box\n",
    "        box_predictions = exists_box * (\n",
    "            best_box * predictions[..., 26:30] + (1 - best_box) * predictions[..., 21:25]\n",
    "        )\n",
    "        box_targets = exists_box * target[..., 21:25]\n",
    "        \n",
    "        # take the square root of the width and height\n",
    "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4] * torch.sqrt(torch.abs(box_predictions[..., 2:4]) + 1e-6))\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "\n",
    "        # (N, S, S, 4) -> (N * S * S, 4)\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim = -2),\n",
    "            torch.flatten(box_targets, end_dim = -2)\n",
    "        )\n",
    "\n",
    "        # ======== For Object Loss ======== # \n",
    "        # predictions[..., 25:26] or predictions[..., 20:21] is the confidence score of the best bbox \n",
    "        pred_box = (\n",
    "            best_box * predictions[..., 25:26] + (1 - best_box) * predictions[..., 20:21]\n",
    "        )\n",
    "        # (N * S * S, 1) -> (N, S, S, 1)\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box),\n",
    "            torch.flatten(exists_box * target[..., 20:21]))\n",
    "\n",
    "        # ======== For No Object Loss ======== #\n",
    "        # take the loss for both boxes -> both of them should know there's no object\n",
    "        # (N, S, S, 1) -> (N, S * S)\n",
    "        # box 1\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 20:21], start_dim = 1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 20:21], start_dim = 1)\n",
    "        )\n",
    "        # box 2\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 25:26], start_dim = 1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 20:21], start_dim = 1)\n",
    "        )\n",
    "\n",
    "        # ======== For Class Loss ======== #\n",
    "        # (N, S, S, 20) -> (N * S * S, 20)\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :20], end_dim = -2),\n",
    "            torch.flatten(exists_box * target[..., :20], end_dim = -2)\n",
    "        )\n",
    "\n",
    "        # ======== Final Loss ======== #\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss # first two rows in the paper\n",
    "            + object_loss # third row in the paper\n",
    "            + self.lambda_noobj * no_object_loss # fourth row in the paper\n",
    "            + class_loss # fifth row in the paper\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
