{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes = 10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 8, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size = (2, 2), stride = (2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3), stride = (1, 1), padding = (1, 1))\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6269821.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 8924754.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2675635.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1962555.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "batch_size = 64\n",
    "train_dataset = datasets.MNIST(root = \"dataset/\", train = True, transform = transforms.ToTensor(), download = True)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"dataset/\", train = False, transform = transforms.ToTensor(), download = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/MNIST/tryingTensorBoard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(64, 28, 28)\n",
    "print(x.shape)\n",
    "print(x.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2746,  0.0790, -0.0251],\n",
       "          [ 0.0658,  0.0482,  0.1482],\n",
       "          [-0.1356, -0.0758, -0.2823]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0337, -0.0841, -0.1851],\n",
       "          [-0.3254, -0.0625,  0.1877],\n",
       "          [ 0.1947, -0.1102, -0.2207]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2357,  0.0770, -0.2787],\n",
       "          [-0.2529, -0.2276, -0.1744],\n",
       "          [-0.3317,  0.1455, -0.0373]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0834, -0.0969, -0.0423],\n",
       "          [-0.1841,  0.2436, -0.2430],\n",
       "          [ 0.2959, -0.0371, -0.1348]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0729,  0.2497,  0.0038],\n",
       "          [ 0.0031,  0.3104,  0.2222],\n",
       "          [ 0.0179,  0.2325,  0.3041]]],\n",
       "\n",
       "\n",
       "        [[[-0.3180,  0.3244, -0.2659],\n",
       "          [-0.2809,  0.1037,  0.2163],\n",
       "          [-0.1241, -0.0637,  0.3039]]],\n",
       "\n",
       "\n",
       "        [[[-0.2209, -0.2882, -0.0856],\n",
       "          [ 0.2616, -0.1542, -0.1353],\n",
       "          [ 0.1673,  0.1327,  0.2075]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1201, -0.2517,  0.1041],\n",
       "          [ 0.3119,  0.2950,  0.2512],\n",
       "          [ 0.0006, -0.0916,  0.1785]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2746,  0.0790, -0.0251],\n",
       "          [ 0.0658,  0.0482,  0.1482],\n",
       "          [-0.1356, -0.0758, -0.2823]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0337, -0.0841, -0.1851],\n",
       "          [-0.3254, -0.0625,  0.1877],\n",
       "          [ 0.1947, -0.1102, -0.2207]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2357,  0.0770, -0.2787],\n",
       "          [-0.2529, -0.2276, -0.1744],\n",
       "          [-0.3317,  0.1455, -0.0373]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0834, -0.0969, -0.0423],\n",
       "          [-0.1841,  0.2436, -0.2430],\n",
       "          [ 0.2959, -0.0371, -0.1348]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0729,  0.2497,  0.0038],\n",
       "          [ 0.0031,  0.3104,  0.2222],\n",
       "          [ 0.0179,  0.2325,  0.3041]]],\n",
       "\n",
       "\n",
       "        [[[-0.3180,  0.3244, -0.2659],\n",
       "          [-0.2809,  0.1037,  0.2163],\n",
       "          [-0.1241, -0.0637,  0.3039]]],\n",
       "\n",
       "\n",
       "        [[[-0.2209, -0.2882, -0.0856],\n",
       "          [ 0.2616, -0.1542, -0.1353],\n",
       "          [ 0.1673,  0.1327,  0.2075]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1201, -0.2517,  0.1041],\n",
       "          [ 0.3119,  0.2950,  0.2512],\n",
       "          [ 0.0006, -0.0916,  0.1785]]]], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[\"conv1.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, device, num_epochs):\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data = data.to(device = device)\n",
    "            targets = targets.to(device = device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(data)\n",
    "            loss = loss_fn(scores, targets)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent or adam step\n",
    "            optimizer.step()\n",
    "\n",
    "            num_correct = (scores.argmax(dim = 1) == targets).sum()\n",
    "            accuracy = num_correct / data.shape[0]\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "\n",
    "            # Scalers\n",
    "            writer.add_scalar(\"Training loss\", loss, global_step =batch_idx)\n",
    "            writer.add_scalar(\"Number of correct\", num_correct, global_step =batch_idx)\n",
    "            writer.add_scalar(\"Accuracy\", accuracy, global_step =batch_idx)\n",
    "            \n",
    "            # Visualizing images and weights\n",
    "            img_grid = torchvision.utils.make_grid(data)\n",
    "            writer.add_image(\"MNIST images\", img_grid, batch_idx)\n",
    "            writer.add_histogram(\"conv1\", model.conv1.weight, global_step =batch_idx)\n",
    "            writer.add_histogram(\"fc1\", model.fc1.weight, global_step =batch_idx)\n",
    "\n",
    "            # Visualize embeddings\n",
    "            features = data.reshape(data.shape[0], -1)\n",
    "            class_labels = [classes[label] for label in targets]\n",
    "            writer.add_embedding(features, metadata = class_labels, label_img = data, global_step =batch_idx)\n",
    "            \n",
    "        # Hyperparams\n",
    "        writer.add_hparams({\"lr\": learning_rate, \"bsize\": batch_size}, {\"accuracy\" : sum(accuracies) / len(accuracies), \"loss\" : sum(losses) / len(losses)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(dataset \u001b[39m=\u001b[39m train_dataset, batch_size \u001b[39m=\u001b[39m batch_size, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruns/MNIST/tryingTensorBoard/batch_size=\u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m, lr=\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m train(model, train_loader, loss_fn, optimizer, device, num_epochs)\n",
      "Cell \u001b[0;32mIn[13], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     features \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreshape(data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m     class_labels \u001b[39m=\u001b[39m [classes[label] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m targets]\n\u001b[0;32m---> 43\u001b[0m     writer\u001b[39m.\u001b[39;49madd_embedding(features, metadata \u001b[39m=\u001b[39;49m class_labels, label_img \u001b[39m=\u001b[39;49m data, global_step \u001b[39m=\u001b[39;49mbatch_idx)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Hyperparams\u001b[39;00m\n\u001b[1;32m     45\u001b[0m writer\u001b[39m.\u001b[39madd_hparams({\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: learning_rate, \u001b[39m\"\u001b[39m\u001b[39mbsize\u001b[39m\u001b[39m\"\u001b[39m: batch_size}, {\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39msum\u001b[39m(accuracies) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(accuracies), \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39msum\u001b[39m(losses) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(losses)})\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:954\u001b[0m, in \u001b[0;36mSummaryWriter.add_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    949\u001b[0m     make_sprite(label_img, save_path)\n\u001b[1;32m    951\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    952\u001b[0m     mat\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    953\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mmat should be 2D, where mat.size(0) is the number of data points\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 954\u001b[0m make_mat(mat, save_path)\n\u001b[1;32m    956\u001b[0m \u001b[39m# Filesystem doesn't necessarily have append semantics, so we store an\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m# internal buffer to append to and re-write whole file after each\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[39m# embedding is added\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_projector_config\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/torch/utils/tensorboard/_embedding.py:72\u001b[0m, in \u001b[0;36mmake_mat\u001b[0;34m(matlist, save_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m matlist:\n\u001b[1;32m     71\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x]\n\u001b[0;32m---> 72\u001b[0m     f\u001b[39m.\u001b[39;49mwrite(tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mas_bytes(\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py:773\u001b[0m, in \u001b[0;36mGFile.write\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_started \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m         \u001b[39m# append the later chunks\u001b[39;00m\n\u001b[0;32m--> 773\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, file_content, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinary_mode)\n\u001b[1;32m    774\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m     \u001b[39m# add to temp file, but wait for flush to write to final filesystem\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_temp \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py:167\u001b[0m, in \u001b[0;36mLocalFileSystem.append\u001b[0;34m(self, filename, file_content, binary_mode)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mappend\u001b[39m(\u001b[39mself\u001b[39m, filename, file_content, binary_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"Append string file contents to a file.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39m        binary_mode: bool, write as binary if True, otherwise text\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_write(filename, file_content, \u001b[39m\"\u001b[39;49m\u001b[39mab\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m binary_mode \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py:173\u001b[0m, in \u001b[0;36mLocalFileSystem._write\u001b[0;34m(self, filename, file_content, mode)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39mopen(filename, mode, encoding\u001b[39m=\u001b[39mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    172\u001b[0m     compatify \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_bytes \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode \u001b[39melse\u001b[39;00m compat\u001b[39m.\u001b[39mas_text\n\u001b[0;32m--> 173\u001b[0m     f\u001b[39m.\u001b[39mwrite(compatify(file_content))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytor/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/compat/__init__.py:37\u001b[0m, in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_np\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorflow_stub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_bytes\u001b[39m(bytes_or_text, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[39m\"\"\"Converts either bytes or unicode to `bytes`, using utf-8 encoding for\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    text.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    TypeError: If `bytes_or_text` is not a binary or unicode string.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(bytes_or_text, \u001b[39mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "num_epochs = 1\n",
    "batch_sizes = [32, 64, 128]\n",
    "learning_rates = [0.001, 0.0001]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        model = CNN(in_channels = in_channels, num_classes = num_classes).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "        train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        writer = SummaryWriter(f\"runs/MNIST/tryingTensorBoard/batch_size={batch_size}, lr={learning_rate}\")\n",
    "        train(model, train_loader, loss_fn, optimizer, device, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Images, Weights and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "model = CNN(in_channels = in_channels, num_classes = num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "writer = SummaryWriter(f\"runs/MNIST/tryingTensorBoard/images_weights\")\n",
    "train(model, train_loader, loss_fn, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da558834fe1f1fe6a302970942de2fa335c2c32197b357720dc1426ec8aea207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
