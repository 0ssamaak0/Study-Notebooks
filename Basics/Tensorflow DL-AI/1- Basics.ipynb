{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 00:19:05.977673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 00:19:05.977974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978134: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978425: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978493: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-14 00:19:05.978535: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-14 00:19:05.979289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units = 1, input_shape = [1])])\n",
    "model.compile(optimizer = \"sgd\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 46.3992\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 36.8849\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 29.3917\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 23.4888\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.8371\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 15.1701\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.2778\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9953\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1927\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7677\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6399\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7462\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0367\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.4723\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0222\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6621\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3729\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1397\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9506\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7963\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6696\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5646\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4769\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4028\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3396\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2850\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2373\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1951\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1574\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1232\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0920\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0631\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0362\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0110\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9871\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9643\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9426\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9217\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9016\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8821\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8633\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8449\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8271\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8098\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7929\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7764\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7602\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7445\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7291\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7140\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6993\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6849\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6708\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6569\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6434\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6302\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6172\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6045\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5921\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5799\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5680\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5564\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5449\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5337\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5228\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5120\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4912\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4811\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4712\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4615\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4521\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4428\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4337\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4248\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4075\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3991\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3909\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3829\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3750\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3673\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3598\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3524\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3452\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3381\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3311\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3243\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3177\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3111\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3047\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2985\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2924\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2864\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2805\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2747\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2691\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2635\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2581\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2528\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2476\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2425\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2376\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2327\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2279\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2232\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2186\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2141\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2097\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2054\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2012\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1971\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1930\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1891\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1852\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1814\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1777\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1740\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1704\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1669\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1635\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1601\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1569\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1536\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1505\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1474\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1444\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1414\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1385\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1356\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1329\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1301\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1275\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1248\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1223\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1198\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1173\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1149\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1125\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1102\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1080\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1057\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1036\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1014\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0994\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0973\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0953\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0934\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0914\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0896\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0877\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0859\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0842\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0824\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0807\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0791\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0775\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0759\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0743\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0728\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0713\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0698\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0684\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0670\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0656\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0643\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0629\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0616\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0604\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0591\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0579\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0567\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0556\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0544\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0533\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0522\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0511\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0501\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0491\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0481\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0471\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0461\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0452\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0442\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0433\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0424\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0416\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0407\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0399\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0390\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0382\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0375\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0367\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0359\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0352\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0345\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0331\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0324\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0317\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0311\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0304\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0298\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0292\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0286\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0280\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0274\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0269\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0263\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0258\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0253\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0247\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0237\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0232\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0228\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0223\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0214\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0210\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0205\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0201\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0197\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0193\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0189\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0177\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0174\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0170\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0167\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0163\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0160\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0157\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0153\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0147\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0141\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0138\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0135\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0133\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0130\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0127\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0125\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0122\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0120\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0117\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0115\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0112\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0110\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0108\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0106\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0103\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0101\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0099\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0097\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0095\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0093\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0091\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0089\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0088\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0086\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0084\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0082\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0081\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0077\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0076\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0074\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0070\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0068\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0067\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0066\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0063\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0062\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0060\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0059\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0058\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0057\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0056\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0054\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0050\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0049\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0047\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0040\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0039\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0038\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0037\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0037\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0036\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0032\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0032\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0031\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0029\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0028\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0026\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0026\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0024\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0024\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0015\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0010\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9128e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.7092e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5097e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.3144e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1231e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.9357e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.7521e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5724e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.3963e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.2238e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0549e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8895e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7274e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5687e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4132e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2609e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1118e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9657e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8226e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6825e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5452e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4108e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2791e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1501e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0238e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.9000e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7789e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6602e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.5439e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4300e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3185e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2093e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.1023e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9975e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8948e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7943e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6958e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5993e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5049e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4123e-04\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3217e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2329e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1460e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0608e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9774e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8957e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8157e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7373e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6605e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5854e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5117e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4396e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3689e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2997e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.2320e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1656e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1006e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0369e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9745e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9134e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8535e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.7949e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7375e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6813e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6262e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5723e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5194e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.4677e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4170e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3673e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3187e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2711e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2244e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1787e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1340e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0901e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0472e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0052e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9640e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9236e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8841e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8454e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8075e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7704e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7340e-04\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6984e-04\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6635e-04\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6294e-04\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5959e-04\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5631e-04\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5310e-04\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4995e-04\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4687e-04\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4386e-04\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4090e-04\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3801e-04\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3517e-04\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3239e-04\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2968e-04\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2701e-04\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2440e-04\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2185e-04\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1934e-04\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1689e-04\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1449e-04\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1214e-04\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0984e-04\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0758e-04\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0537e-04\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0321e-04\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0109e-04\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.9010e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6976e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4983e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3033e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1122e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9250e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7416e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5621e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3863e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.2139e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0453e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8801e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7181e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5597e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4043e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2522e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1032e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9574e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8143e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6744e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5373e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.4031e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2716e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a184bfee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18.976892]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: object recognition & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth = 200)\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affects Accuracy\n",
    "train_images =  train_images / 255.0\n",
    "test_images =  test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation = tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.optimizers.Adam(), loss = tf.losses.sparse_categorical_crossentropy, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5273 - accuracy: 0.8206\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3905 - accuracy: 0.8599\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3499 - accuracy: 0.8734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcf6c41cbb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3241 - accuracy: 0.8827\n",
      "Epoch 2/3\n",
      "  78/1875 [>.............................] - ETA: 9s - loss: 0.2907 - accuracy: 0.8878"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/TensorFlow Specialization/Course1.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/TensorFlow%20Specialization/Course1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mCPU\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/TensorFlow%20Specialization/Course1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train_images, train_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3531327247619629, 0.8723999857902527]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get(\"loss\") < 0.4):\n",
    "            print(\"Cancel training, loss is low\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1857/1875 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8734Cancel training, loss is low\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3511 - accuracy: 0.8736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40943b3d90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_backs = myCallback()\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks = [call_backs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'call_backs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/TensorFlow Specialization/Course1.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/TensorFlow%20Specialization/Course1.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m call_backs\u001b[39m.\u001b[39mon_epoch_end()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'call_backs' is not defined"
     ]
    }
   ],
   "source": [
    "call_backs.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing learning_rate per epoch\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10 ** (epoch / 20))\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks = [lr_schedule])\n",
    "\n",
    "# then, plot the loss vs learning_rate, choose the best value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week3: CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\", input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.optimizers.Adam(), loss = tf.losses.sparse_categorical_crossentropy, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8958Cancel training, loss is low\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2820 - accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "call_backs = myCallback()\n",
    "histroy = model.fit(train_images, train_labels, epochs=5, callbacks = [call_backs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff08abbdd30>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img = 0\n",
    "second_img = 23\n",
    "third_img = 28\n",
    "conv_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the layers as the outputs of the model\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 26, 26, 64) dtype=float32 (created by layer 'conv2d')>,\n",
       " <KerasTensor: shape=(None, 13, 13, 64) dtype=float32 (created by layer 'max_pooling2d')>,\n",
       " <KerasTensor: shape=(None, 11, 11, 64) dtype=float32 (created by layer 'conv2d_1')>,\n",
       " <KerasTensor: shape=(None, 5, 5, 64) dtype=float32 (created by layer 'max_pooling2d_1')>,\n",
       " <KerasTensor: shape=(None, 1600) dtype=float32 (created by layer 'flatten')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'dense')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_1')>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "f1 = activation_model.predict(test_images[1].reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26, 26, 64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(3,4, figsize = (10,10))\n",
    "\n",
    "for i in range(0,4):\n",
    "    f1 = activation_model.predict(test_images[1].reshape(1,28,28,1))[i];\n",
    "    axes[0,i].imshow(f1[0,:,:,conv_num], cmap = \"inferno\");\n",
    "\n",
    "    f2 = activation_model.predict(test_images[second_img].reshape(1,28,28,1))[i];\n",
    "    axes[1,i].imshow(f2[0,:,:,conv_num], cmap = \"inferno\");\n",
    "\n",
    "    f3 = activation_model.predict(test_images[third_img].reshape(1,28,28,1))[i];\n",
    "    axes[2,i].imshow(f3[0,:,:,conv_num], cmap = \"inferno\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-14 18:21:42--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.37.240, 172.217.18.48, 172.217.18.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.37.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: horse-or-human.zip\n",
      "\n",
      "horse-or-human.zip  100%[===================>] 142.65M  1.79MB/s    in 90s     \n",
      "\n",
      "2022-09-14 18:23:13 (1.58 MB/s) - horse-or-human.zip saved [149574867/149574867]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip the dataset\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Do the same for validation data\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./horse-or-human/\",\n",
    "    # set target size to 150 to compact data , but it will overfit\n",
    "    target_size =(300,300),\n",
    "    batch_size = 128,\n",
    "    class_mode = \"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 18:26:45.408325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:45.480034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:45.480625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:45.482448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 18:26:45.485281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:45.485707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:45.486034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:46.766444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:46.766835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:46.766850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-09-14 18:26:46.767126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-14 18:26:46.767188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3943 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activationb='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer= tf.keras.optimizers.RMSprop(learning_rate = 0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 9.0153e-04 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 5.0639e-04 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 2.3855e-04 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.0798e-04 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.7409 - accuracy: 0.9248\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0344 - accuracy: 0.9889\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 5.5991e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 3.8010e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 1.8492e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 7.1975e-05 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 5.5100e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 2.4424e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4414dab3a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if validation, you will get val loss and accuracy too\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    # when the training set has no fixed size\n",
    "    steps_per_epoch = 8,\n",
    "    epochs = 15,\n",
    "    verbose = 1\n",
    "    \n",
    "    # if validation\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting an image\n",
    "image = tf.keras.preprocessing.image.load_img(\"Horse.png\", target_size = (300,300))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image) / 255\n",
    "image = image[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 459ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compacting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
